#!/bin/bash
#SBATCH --job-name=__name                         # Job name
#SBATCH --account=__slurm_account                    # Tracking account
#SBATCH -N__nodes -n__ntasks                                # Number of nodes and cores required, respectively
#SBATCH --mem=__slurm_memory                       # Memory per core
#SBATCH --time=__slurm_time                      # Duration of the job (Ex: 15 mins)
#SBATCH -p__slurm_partition                         # Queue name (where job is submitted)
#SBATCH -o__name.out                         # Combined output and error messages file

cd $SLURM_SUBMIT_DIR                            # Change to working directory

if [ -f 'info.out' ]; then
  rm info.out
fi

echo "Working directory: ${SLURM_SUBMIT_DIR}" >> info.out
echo "Scratch space: ${TMPDIR}" >> info.out
echo "Job Name: ${SLURM_JOB_NAME}" >> info.out
echo "Job ID: ${SLURM_JOB_ID}" >> info.out
echo "Start time: ${SLURM_JOB_START_TIME}" >> info.out

module load anaconda3/2023.03
conda activate dlpno_memtest			      # Load module dependencies
__psi_build __name.py --loglevel=10 -n 8 --scratch ${TMPDIR}
